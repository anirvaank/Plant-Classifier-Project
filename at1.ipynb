{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: pandas in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (2.2.3)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.1-cp312-cp312-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anirv\\onedrive\\desktop\\sem 5\\intro to machine learning\\project\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading matplotlib-3.9.3-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/7.8 MB 1.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/7.8 MB 1.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/7.8 MB 1.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.3/7.8 MB 1.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.8/7.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.4/7.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.4/7.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.6/7.8 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.9/7.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.7/7.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 4.5/7.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.5/7.8 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 6.8/7.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/38.8 MB 5.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/38.8 MB 6.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 3.9/38.8 MB 6.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.2/38.8 MB 6.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.6/38.8 MB 6.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.1/38.8 MB 5.8 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 7.9/38.8 MB 5.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.1/38.8 MB 4.9 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 8.7/38.8 MB 4.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 8.9/38.8 MB 4.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 9.4/38.8 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.2/38.8 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.5/38.8 MB 4.0 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 10.7/38.8 MB 3.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.3/38.8 MB 3.7 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 12.3/38.8 MB 3.7 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 13.1/38.8 MB 3.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 13.9/38.8 MB 3.7 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 14.7/38.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 15.7/38.8 MB 3.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.5/38.8 MB 3.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.0/38.8 MB 3.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.3/38.8 MB 3.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.3/38.8 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.1/38.8 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 18.9/38.8 MB 3.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 19.7/38.8 MB 3.5 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 20.7/38.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.5/38.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 22.3/38.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 23.1/38.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.6/38.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.6/38.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 26.0/38.8 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 27.0/38.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 28.0/38.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 29.1/38.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.1/38.8 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.8 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.0/38.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.6/38.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/38.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.6/38.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.4/38.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.8 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.0/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, opencv-python, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.1 kiwisolver-1.4.7 matplotlib-3.9.3 opencv-python-4.10.0.84 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (if not already installed)\n",
    "%pip install torch torchvision pandas matplotlib opencv-python Pillow\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     image:FILE  category\n",
      "0  train/aloevera/aloevera0.jpg         0\n",
      "1  train/aloevera/aloevera1.jpg         0\n",
      "2  train/aloevera/aloevera2.jpg         0\n",
      "3  train/aloevera/aloevera3.jpg         0\n",
      "4  train/aloevera/aloevera4.jpg         0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "val_df = pd.read_csv('dataset/val.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Preview the structure\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for loading plant images.\n",
    "        Args:\n",
    "        - dataframe: Pandas DataFrame with columns [image:FILE, category]\n",
    "        - root_dir: Base directory containing the images (e.g., 'dataset/')\n",
    "        - transform: Torchvision transforms for data augmentation\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Combine root_dir and image:FILE column to get full path\n",
    "        img_path = os.path.join(self.root_dir, self.data.iloc[idx, 0])  # First column = image path\n",
    "        label = self.data.iloc[idx, 1]  # Second column = category (numeric)\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files into dataframes\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "val_df = pd.read_csv('dataset/val.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PlantDataset(dataframe=train_df, root_dir='dataset/train', transform=transform)\n",
    "val_dataset = PlantDataset(dataframe=val_df, root_dir='dataset/val', transform=transform)\n",
    "test_dataset = PlantDataset(dataframe=test_df, root_dir='dataset/test', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.PlantDataset object at 0x0000020EBBA58E90>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CSV files into dataframes\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "val_df = pd.read_csv('dataset/val.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PlantDataset(dataframe=train_df, root_dir='dataset/', transform=transform)\n",
    "val_dataset = PlantDataset(dataframe=val_df, root_dir='dataset/', transform=transform)\n",
    "test_dataset = PlantDataset(dataframe=test_df, root_dir='dataset/', transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'aloevera', 1: 'banana', 2: 'bilimbi', 3: 'cantaloupe', 4: 'cassava', 5: 'coconut', 6: 'corn', 7: 'cucumber', 8: 'curcuma', 9: 'eggplant', 10: 'galangal', 11: 'ginger', 12: 'guava', 13: 'kale', 14: 'longbeans', 15: 'mango', 16: 'melon', 17: 'orange', 18: 'paddy', 19: 'papaya', 20: 'peperchili', 21: 'pineapple', 22: 'pomelo', 23: 'shallot', 24: 'soybeans', 25: 'spinach', 26: 'sweetpotatoes', 27: 'tobacco', 28: 'waterapple', 29: 'watermelon'}\n"
     ]
    }
   ],
   "source": [
    "# List of class names in the order 0-29\n",
    "class_names = [\n",
    "    \"aloevera\", \"banana\", \"bilimbi\", \"cantaloupe\", \"cassava\", \"coconut\", \"corn\", \"cucumber\",\n",
    "    \"curcuma\", \"eggplant\", \"galangal\", \"ginger\", \"guava\", \"kale\", \"longbeans\", \"mango\", \n",
    "    \"melon\", \"orange\", \"paddy\", \"papaya\", \"peperchili\", \"pineapple\", \"pomelo\", \"shallot\",\n",
    "    \"soybeans\", \"spinach\", \"sweetpotatoes\", \"tobacco\", \"waterapple\", \"watermelon\"\n",
    "]\n",
    "\n",
    "# Create a mapping of class IDs (0-29) to names\n",
    "class_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "# Display the mapping\n",
    "print(class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PlantClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PlantClassifier(num_classes=30).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.6888\n",
      "Epoch 2/10, Loss: 1.8638\n",
      "Epoch 3/10, Loss: 1.1352\n",
      "Epoch 4/10, Loss: 0.6213\n",
      "Epoch 5/10, Loss: 0.3741\n",
      "Epoch 6/10, Loss: 0.2534\n",
      "Epoch 7/10, Loss: 0.1873\n",
      "Epoch 8/10, Loss: 0.1498\n",
      "Epoch 9/10, Loss: 0.1517\n",
      "Epoch 10/10, Loss: 0.1321\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 68.03%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'spinach'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'coconut'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'spinach'}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "sample_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            sample_predictions.append({\n",
    "                \"True Label\": class_mapping[labels[i].item()],\n",
    "                \"Predicted\": class_mapping[predicted[i].item()]\n",
    "            })\n",
    "        break  # Just preview one batch\n",
    "\n",
    "# Display sample predictions\n",
    "for pred in sample_predictions[:5]:  # Show first 5 predictions\n",
    "    print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as plant_classifier.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'plant_classifier.pth2')\n",
    "print(\"Model saved as plant_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anirv\\AppData\\Local\\Temp\\ipykernel_11180\\3744957548.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('plant_classifier.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('plant_classifier.pth'))\n",
    "model.eval()\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.88%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'spinach'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'coconut'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'spinach'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'peperchili'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'mango'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'soybeans'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'spinach'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'guava'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'galangal'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'aloevera'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'spinach'}\n",
      "{'True Label': 'aloevera', 'Predicted': 'cucumber'}\n"
     ]
    }
   ],
   "source": [
    "for pred in sample_predictions[:100]:  # Show first 5 predictions\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.cuda.memory.empty_cache() -> None>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
